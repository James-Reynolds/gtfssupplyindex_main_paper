---
title: "Leveraging GTFS data to assess transit supply"
author:
  - name: James Reynolds
    email: james.reynolds@monash.edu
    affiliation: Public Transport Research Group (PTRG)
    correspondingauthor: true
    footnote: 1
  - name: Yanda Qu
    email: yanda.qu@monash.edu
    affiliation: Public Transport Research Group (PTRG)
    footnote: 2
  - name: Graham Currie
    email: graham.currie@monash.edu
    affiliation: Public Transport Research Group (PTRG)
    footnote: 3
address:
  - code: Public Transport Research Group (PTRG)
    organization: Public Transport Research Group (PTRG), Institute of Transport Studies, Department of Civil Engineering Engineering, Monash University
    addressline: Clayton Campus
    city: Melbourne 
    state: Victoria
    postcode: 3800
    country: Australia
  
footnote:
  - code: 1
    text: "Research Fellow"
  - code: 2
    text: "PhD Strudent"
  - code: 3
    text: "Professor"
abstract: |
  This is the abstract.

  It consists of two paragraphs.
keywords: 
  - keyword1
  - keyword2
journal: "Transport Geography?"
date: "`r Sys.Date()`"
classoption: preprint, 3p, authoryear
bibliography: References.bib, packages.bib
linenumbers: false
numbersections: true
# Use a CSL with `citation_package = "default"`
# csl: https://www.zotero.org/styles/elsevier-harvard
output: 
  rticles::elsevier_article:
    keep_tex: true
    citation_package: natbib
    extra_dependencies: "subfig"
---



```{r setup, include=FALSE}
library(tidyverse)
library(tidytransit)
library(sp)
library(strayr)
library(ptinpoly)
library(magrittr)
library(ggplot2)
library(sf)
library(ASGS.foyer)
library(raster)
library(ggmap)
library(units)
library(janitor)
library(mapview)
library(ggstatsplot)
library(gtsummary)
library(moments)
library(scales)
library(gtfstools)
library(lubridate)
library(kableExtra)
library(knitr)
library(readxl)
library(dplyr)
library(devtools)
library(gtfssupplyindex)
library(readabs)
library(gglorenz)
library(DescTools)
# invalidate cache when the tufte version changes
#knitr::opts_chunk$set(cache.extra = packageVersion('tufte'))

```



# Introduction
"If you can't measure it, you can't manage it" 
is often miss-attributed to @Deming1993new who, 
according to @Berenson2016,
was actually trying to
make the opposite point. 
Regardless,
service level indicators 
are important in
researching, 
managing 
and seeking to improve transit operations 
[@FieldingGordonJ1987Mpts; @Ryus:2003aa]. 
Many indicators already exist 
including, for example: 
those in the Transit Capacity and Quality of Service Manual (TCQSM)[@TCQSM:2013]; and
the Transit Score metric [@WalkScore:2023tg]. There are two inter-related challenges
in using such metrics: 
(1) calculating the scores themselves 
for a specific location 
and service pattern; and
(2) understanding the metrics, 
their meaning 
and importance 
(and being able to explain this
to those who 
are not specialists in transit).
For example:
the TCQSM metrics 
might fail the first challenge, 
being difficult to calculate 
without specialist software and data. 
However, they use an A to F scoring system 
and there is an entire guidebook 
explaining each individual indicator, 
suggesting that they might pass the second. 
In contrast, 
entering an address into the Transit Score website 
will return a score out of 100 
reflecting the quantity of transit available, which is both easy to obtain and explain. 
However, the methodology and algorithm 
behind the Transit Score is 
not publicly available, 
so these cannot be calculated independently.
This might limit 
practitioners, researchers, advocates or
others involved in transit planning, 
operations or policy-making 
from reporting score changes 
associated with new infrastructure, 
service patterns or 
improvement options.  

Previous research by @currie2007identifying 
developed a transit Supply Index (SI), 
This appears relatively easy to understand 
and explain, as it is based 
on the number of transit arrivals 
at stops within an area of interest.  
An adjustment is made to account 
for how much of the area of interest is
within walking distance of each stop, 
meaning that higher SI scores indicate 
areas with more frequent services 
and/or better coverage. 

Unfortunately, 
the SI does not appear to have been widely used,
perhaps in part because at the time it was first published it was not particulrly easy to calculate. 
At that time timetable data was not publicly available 
in a standardized 
and machine-readable format, and 
the scores reported in Currie and Senbergs (2007)
were calculated directly from a database of services provided by the transit authority 
in Melbourne, Australia. 
Nowadays, 
the General Transit Feed Specification (GTFS) 
allows timetable publication in a standardized format, 
with more than 10,000 agencies 
providing feeds^[There are two forms: 
GTFS-static consisting of the timetable data (the scheduled services); 
and GTFS-realtime, which includes vehicle arrivals and departure times based on real-world position data. 
This paper and project uses only the GTFS-static (timetable) format.] 
[@GTFS], 

Many visualization, processing and analysis tools 
that accept GTFS data are now available. 
A gap, however, is that 
there is not yet a tool to calculate SI scores directly from 
GTFS datasets.
This provides the motivation 
for the research reported in this paper, 
in which a new R package (gtfssupplyindex) 
specifically developed to calculate SI scores 
is presented. 
The remainder of this paper is structured as follows:
the next section outlines the background to this research,
including the original formulation of the Transit Supply Index, 
and an explanation of the GTFS. 
Section 3 then describes the study methodology, 
followed by a brief presentation of results in Section 4. 
Section 5 discusses the results, 
outlines directions for future research 
and provides a brief conclusion. 

# Background

## Transit metrics
Even a brief search reveals 
many metrics 
available for benchmarking transit services. 
Examples include: 
(1) those in the Transit Cooperative Research Program (TCRP) Report 88, which is an extensive guidebook on developing a performance-measurement system [@Ryus:2003aa]; 
(2) online databases provided by 
the Florida Transit Information System (FTIS) [@Florida-Transit-Information-System:2018aa] 
and @UITP:2015aa; 
(3) those used in the extensive annual benchmarking program
undertaken yearly by the Transport Strategy Centre in the United Kingdom, 
including over 100 transit providers around the world [@Imperial-College-London:2023aa]; and
(4) a recently developed methodology to calculate 'blank spots' within an area, 
being those places beyond 400/800 metre walking distances to/from bus and tram stops/train stations [@AlamriSultan2023GAoA]. 
  
  
The Fielding Triangle [@FieldingGordonJ1987Mpts] 
provides a framework 
for understanding how such metrics combine 
service inputs, 
outputs 
and consumption 
to describe cost efficiency 
and effectiveness; and
service effectiveness. 
More broadly 
@Litman:2003ab 
and @Litman:2016aa 
discuss some of the traffic, 
mobility, 
accessibility, 
social equity, 
strategic planning 
and other rational decision-making-based
perspectives underling such metrics, 
while @Reynolds:2017ah extends 
these into models of how 
institutionalism, 
incrementalism 
and other public policy analysis concepts 
might apply to decision-making processes 
relating to transit prioritisation. 
@GuzmanLuisA.2017Aeit, 
developed a measure of accessibility 
in the context of policy development 
and social equity 
for Latin American Bus Rapid Transit (BRT) networks, while @Creutzig2020streetspaceallocation
introduced street space allocation metrics 
based around 10 ethical principles 

However, 
many of these metrics appear difficult to calculate, complex to explain or understand, 
and likely not well suited to communication 
with those who are not transit planners or engineers, 
or other technical specialists. 
Where pre-calculated metrics 
are immediately available 
it may not be possible for  practitioners, 
researchers 
or advocates 
to independently generate metrics 
for proposed system changes. 
Sometimes it is not even possible 
to know precisely how scores for the existing services levels are calculated. 
For example, 
Transit Scores 
for locations with a published GTFS feed 
are readily available on the @WalkScore:2023tg website, 
eliminating the need for any calculations. 
The meaning of these Transit Scores 
appears easy to explain, 
as the highest possible score of 100 
represents what might be experienced in the centre of New York. 
However, 
the Transit Score algorithm 
is patented 
and effectively a black box. 
It is not possible to calculate Transit Scores scores independently. 
Nor can Transit Scores to be generated 
for proposed changes to networks. 
The Transit Score metric, therefore, 
fails the first of the aforementioned challenges, 
as practitioners, researchers and advocates 
can only use those scores provided online.
But, because it is based on 
a patented algorithm it may not be easy to understand or explain 
the connection between real-world conditions 
and the Transit Score, 
or what might need to be done 
to improve the score (and service levels). 
As such, it might partially 
pass the second of the aforementioned challenges, 
as the score's concept is simple-  
the closer to 100, the better -
but further detail is limited.  

In contrast, the TCQSM, 
specifies Levels of Service (LOS) 
between A and F 
across a range of factors^[
Including service span, 
frequency, 
speed, 
the proportion of the population serviced, 
competitiveness of travel times to car-based travel, 
and many more.]. 
This scoring scheme appears relatively simple to explain -
A is good and F is bad - 
and matches that often used in traffic capacity analysis. 
Extensive detail is provided 
within @TCQSM:2013 
scores mean. 
However, 
calculation of many of TCQSM metrics may need specialised software 
and datasets^[
For example, 
the Service Coverage Area metric in the TCQSM (pp. 5-8 to 5-21) 
may require GIS or other analysis, 
on top of accurate data about population densities, 
stop locations 
and service schedules.] 
and it might be challenging to explain 
the detail of these measures 
or how to improve them 
to non-technical decision-makers, 
stakeholders 
or others involved in transit management or advocacy. 

## GTFS
The General Transit Feed Specification (GTFS)
is an open, 
text-based format 
that was developed originally to allow transit information to be included in the Google Maps navigation platform [@GTFS]. Figure \@ref(fig:GTFS_ERD) shows 
an Entity Relationship Diargram (ERD) 
of the GTFS data structure, 
in which each box represents 
a database table 
in the GTFS. 
Table rows 
indicate the variables (columns) 
included in each, 
for example  
each record in the 'stops' table 
includes a value for stop_id, 
stop_name, 
stop_lat and 
stop_lon. 
Relationships between the tables 
are indicated by the connecting lines, 
and Primary Key (PK) and Foreign Key (FK) designations, 
for example, 
stop_id appears in the 'stops' and 'stop_times' tables as a 
Primary Key and Foreign Key. 
`Crow's feet' 
indicate the relationships between each table^[
See https://i.stack.imgur.com/fxaAq.png for guide to the symbols.]

```{r GTFS_ERD, crop = TRUE, fig.cap = "GTFS entity relationship diagram. Source: adapted by author from Alamri et al (2023) and the GTFS Schedule Reference (16/11/2023 revision).", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, out.width='100%'}
knitr::include_graphics("graphics/GTFS.png")

```

GTFS allows individual transit systems 
to be included in many online products and analysis, 
including the Transit Score metric itself. 
@Wong:2013aa provides another example of what can be done with GTFS data, 
having developed code to calculate of some of the TCQSM metrics 
and compared these
across 50 transit operators.
The @Wong:2013aa code is readily available (
https://github.com/jcwong86/GTFS_Explore_Tool),  
but does not appear to be currently maintained. 
Future research may involve 
reviewing this code 
and using it to analyse modern GTFS feeds,  
but in this paper the aim is more modest, 
being to use GTFS data to calculate Currie and Senbergs' (2007) SI.   


## The Transit Suppy Index
Currie and Senbergs' (2007) focus 
was the context of Melbourne's Census Collection Districts (CCD) and calculations based on a week of transit service. A more generalized form of the Transit Supply Index (SI) is shown below: 

  $$SI_{area, time} = \sum{\frac{Area_{Bn}}{Area_{area}}*SL_{n, time}}$$

(1) $SI_{area, time}$ is the Supply Index for the area of interest 
and a given period of time;
(2) $Area_{Bn}$ is the buffer area for each stop (n) within the area of interest. 
In Currie and Senbergs (2007) this was based on 
a radius of 400 metres for bus and tram stops, 
and 800 metres for railway stations;
(3) $Area_{area}$ is the area of the area of interest; and
(4) $SL_{n,time}$ is the number of transit arrivals for each stop 
for a given time period.

An advantage of the SI is 
that it is a relatively simple number 
to calculate, 
understand 
and explain. 
It describes 
the number of transit arrivals 
at stops within 
an area of interest 
and time frame, 
multiplied by a factor 
accounting for the proportion of the area of interest 
that is within typical walking distances of each stop. 
Hence, 
more services, 
more stops 
and higher frequencies 
increase the score. 

The SI score does not incorporate 
service span, 
speed 
or other elements of a transit service. 
While these can be important 
to passenger experience, 
they might add complexity. 
Simplicity is also helped 
by the way 
that the SI is additive, 
in that $SI_{area, time}$ scores can be aggregated 
to calculate an overall score 
across multiple time periods 
or for a region encompassing multiple areas of interest. 


# Methodology
This study 
developed a package 
with tools for calculating the SI from GTFS data. 
The R programming language [@R-base], 
was adopted for code development, and the package development setup and workflow described by @wickham2023r 
was adopted. 
Various existing packages 
were relied upon including: 
the sf package [@R-sf] for geospatial analysis; 
the tidyverse [@tidyverse2019]; 
gtfstools [@R-gtfstools]; and 
tidytransit [@R-tidytransit]. 
Some code was adapted from 
examples, vignettes and other documentation 
in the tidytransit, gtfstools and other packages.

Two cases where used during the code development and testing 
such that results might be generated for real GTFS data: 
the Mornington Peninsula Tourist Railway GTFS feed 
and the Public Transport Victoria (PTV) GTFS feed, 
both in Victoria, Australia. 
Both were selected primarily for convenience, 
given that the authors are familiar with 
the typical service patterns and geography.

Figure \@ref(Melbourne_map)) shows the areas of interest for which results are presented in this paper, including Greater Melbourne and its SA3 zones (main), SA1 zones in the central part of Melbourne (top-right) and the Mornington Peninsula Railway and SA1 zones within 800 metres (bottom-right) . Stations are shown in 


```{r Melbourne_map, fig.cap = "Areas of interest",  echo = FALSE, warning=FALSE, message=FALSE, cache=FALSE, out.width='100%'}

knitr::include_graphics("graphics/all_maps.png")

```

Further cases were selected as 
leading, 
representative 
and contrasting examples 
for the results reported here. 







## Mornington Penninsula Tourist Railway

The Morning Peninsula Tourist Railway 
is in the outer south-east of Melbourne, 
running on Sundays and Wednesdays 
between Mornington and Moorooduc, 
with an intermediate stop at Tanti Park 
(see https://transitfeeds.com/p/mornington-railway/806/latest/stops). 
A GTFS feed from 2018 
was selected for the purposes of tests and demonstrating the code and output.
Australian Bureau of Statistics (ABS) data was also used, 
sources via the strayr 
and absmapsdata packages [@r-strayr].
The Mornington Peninsular Statistical Area 3 (SA3) zone 
and the Statistical Area 1 (SA1) zones contained within it 
were adopted as the areas of interest. 
These are shown in Figure \@ref(fig:mornington_map_ABS), 
together with the locations of the three railway stations.  

```{r mornington_calc, crop = TRUE, fig.cap = "SA1 zones (red), location of Mornington Tourist Railway Stations (black) and boundary of zones within 800m catchment (blue)", fig.width = 3, echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}
### ---------------- get abs data for Mornington Peninsula
#options(timeout = 1000)
#remotes::install_github("wfmackey/absmapsdata")

#get_mornington_sa1 <- function(){
#  mornington_sa12021 <- absmapsdata::sa12021 %>% filter(sa3_name_2021 == "Mornington Peninsula") %>% select(sa1_code_2021)
#  sf::st_write(mornington_sa12021, "inst/extdata/mornington_sa12021.geojson", append=FALSE)
#  return(mornington_sa12021)
#}
#get_mornington_sa3 <- function(){
#  mornington_sa32021 <- absmapsdata::sa32021 %>% filter(sa3_name_2021 == "Mornington Peninsula") %>% select(sa3_code_2021)
#  sf::st_write(mornington_sa32021, "inst/extdata/mornington_sa32021.geojson", append=FALSE)
#  return(mornington_sa32021)
#}

### ---------------- load SA3 abs maps data for just mornington peninsula
areas_of_interest <- load_areas_of_interest(areas_of_interest = absmapsdata::sa12021 %>% filter(sa3_name_2021 == "Mornington Peninsula") %>% select(sa1_code_2021), 
  area_id_field = "sa1_code_2021")

# map the areas_of_interest
map <- areas_of_interest %>% 
  ggplot() +
  geom_sf(aes(geometry = geometry))
#map
#set the EPSG to transform from lat/lon to metres
EPSG_for_transform = 28355

#load the revised mornington GTFS data
list_gtfs = gtfssupplyindex:::gtfs_by_route_type(system.file(
  "extdata/mornington180109",
  "gtfs.zip", 
  package = "gtfssupplyindex", 
  mustWork = TRUE))
stops_as_sf_mornington <-  list_gtfs[[1]]$stops %>% 
  tidytransit::stops_as_sf()

#map the stops on the ABS data
#map + 
#  geom_sf(data = stops_as_sf_mornington, aes(geometry = geometry))


stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355
)

```


## Public Transport Victoria (PTV)
Larger scale testing was performed using the Victorian GTFS feed, 
published by Public Transport Victoria (PTV), 
sourced via @transitfeeds_victoria:2023aa for historical feeds. 
Again, ABS data was used as the areas of interest, focusing on SA1 zones within Greater Melbourne. Data was analysed for the second Tuesday in August each year, so as to match the typical date of the Australian census. 

```{r fix_ptv_data_Victoria_230804, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

ptv_230804 <- tidytransit::read_gtfs("data/ptv_230804/gtfs.zip")
# This results in "Warning: Duplicated ids found in: stops The returned object is not a tidygtfs object, you can use as_tidygtfs() after fixing the issue."

#So, remove the duplicated stops 
#identify duplicate stops
ptv_230804_duplicated_stops <- tabyl(ptv_230804$stops$stop_id) %>% filter (n>1)
names(ptv_230804_duplicated_stops) <- c("stop_id", "n", "percent")
ptv_230804_duplicated_stops <- left_join(ptv_230804_duplicated_stops, ptv_230804$stops)

##discard duplicates
ptv_230804$stops <- ptv_230804$stops[!duplicated(ptv_230804$stops$stop_id),]

## Write gtfs back to file
ptv_230804 <- as_tidygtfs(ptv_230804)
tidytransit::write_gtfs(ptv_230804, "data/ptv_230804/gtfs_duplicate_stops_removed.zip")

## convert to list of tidygtfs objects
ptv_230804_list_gtfs <- gtfssupplyindex::gtfs_by_route_type("data/ptv_230804/gtfs_duplicate_stops_removed.zip")

list_gtfs = ptv_230804_list_gtfs

areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)

```

```{r run_for_all_modes_Victoria_230808, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

si_by_area_and_hour_230808 <- hourly(
  list_gtfs = list_gtfs, 
  stops_in_or_near_areas = stops_in_or_near_areas, 
  date_ymd = "2023-08-08",
  verbose = TRUE)

write.csv(si_by_area_and_hour_230808, "results/Greater_Melbourne/si_by_SA12021area_and_hour_230808")

si_by_area_and_hour_230808_tram <- hourly(
  list_gtfs = list_gtfs[1], 
  stops_in_or_near_areas = stops_in_or_near_areas[1], 
  date_ymd = "2023-08-08",
  verbose = TRUE)

write.csv(si_by_area_and_hour_230808_tram, "results/Greater_Melbourne/si_by_SA12021area_and_hour_230808_tram")

si_by_area_and_hour_230808_rail <- hourly(
  list_gtfs = list_gtfs[2], 
  stops_in_or_near_areas = stops_in_or_near_areas[2], 
  date_ymd = "2023-08-08",
  verbose = TRUE)

write.csv(si_by_area_and_hour_230808_rail, "results/Greater_Melbourne/si_by_SA12021area_and_hour_230808_rail")

si_by_area_and_hour_230808_bus <- hourly(
  list_gtfs = list_gtfs[3], 
  stops_in_or_near_areas = stops_in_or_near_areas[3], 
  date_ymd = "2023-08-08",
  verbose = TRUE)

write.csv(si_by_area_and_hour_230808_bus, "results/Greater_Melbourne/si_by_SA12021area_and_hour_230808_bus")

```

```{r fix_ptv_data_Victoria_220804, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

ptv_220804 <- tidytransit::read_gtfs("data/ptv_220804/gtfs.zip")
# This results in "Warning: Duplicated ids found in: stops The returned object is not a tidygtfs object, you can use as_tidygtfs() after fixing the issue."

#So, remove the duplicated stops 
#identify duplicate stops
ptv_220804_duplicated_stops <- tabyl(ptv_220804$stops$stop_id) %>% filter (n>1)
names(ptv_220804_duplicated_stops) <- c("stop_id", "n", "percent")
ptv_220804_duplicated_stops <- left_join(ptv_220804_duplicated_stops, ptv_220804$stops)

##discard duplicates
ptv_220804$stops <- ptv_220804$stops[!duplicated(ptv_220804$stops$stop_id),]

## Write gtfs back to file
ptv_220804 <- as_tidygtfs(ptv_220804)
tidytransit::write_gtfs(ptv_220804, "data/ptv_220804/gtfs_duplicate_stops_removed.zip")

## convert to list of tidygtfs objects
ptv_220804_list_gtfs <- gtfssupplyindex::gtfs_by_route_type("data/ptv_220804/gtfs_duplicate_stops_removed.zip")

list_gtfs = ptv_220804_list_gtfs

areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)

```

```{r run_for_all_modes_Victoria_200809, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

si_by_area_and_hour_200809 <- hourly(
  list_gtfs = list_gtfs, 
  stops_in_or_near_areas = stops_in_or_near_areas, 
  date_ymd = "2022-08-09",
  verbose = TRUE)

write.csv(si_by_area_and_hour_200809, "results/Greater_Melbourne/si_by_SA12021area_and_hour_200809")

si_by_area_and_hour_200809_tram <- hourly(
  list_gtfs = list_gtfs[1], 
  stops_in_or_near_areas = stops_in_or_near_areas[1], 
  date_ymd = "2022-08-09",
  verbose = TRUE)

write.csv(si_by_area_and_hour_200809_tram, "results/Greater_Melbourne/si_by_SA12021area_and_hour_200809_tram")

si_by_area_and_hour_200809_rail <- hourly(
  list_gtfs = list_gtfs[2], 
  stops_in_or_near_areas = stops_in_or_near_areas[2], 
  date_ymd = "2022-08-09",
  verbose = TRUE)

write.csv(si_by_area_and_hour_200809_rail, "results/Greater_Melbourne/si_by_SA12021area_and_hour_200809_rail")

si_by_area_and_hour_200809_bus <- hourly(
  list_gtfs = list_gtfs[3], 
  stops_in_or_near_areas = stops_in_or_near_areas[3], 
  date_ymd = "2022-08-09",
  verbose = TRUE)

write.csv(si_by_area_and_hour_200809_bus, "results/Greater_Melbourne/si_by_SA12021area_and_hour_200809_bus")

```

```{r fix_ptv_data_Victoria_210805, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

ptv_210805 <- tidytransit::read_gtfs("data/ptv_210805/gtfs.zip")
# This results in "Warning: Duplicated ids found in: stops The returned object is not a tidygtfs object, you can use as_tidygtfs() after fixing the issue."

#So, remove the duplicated stops 
#identify duplicate stops
ptv_210805_duplicated_stops <- tabyl(ptv_210805$stops$stop_id) %>% filter (n>1)
names(ptv_210805_duplicated_stops) <- c("stop_id", "n", "percent")
ptv_210805_duplicated_stops <- left_join(ptv_210805_duplicated_stops, ptv_210805$stops)

##discard duplicates
ptv_210805$stops <- ptv_210805$stops[!duplicated(ptv_210805$stops$stop_id),]

## Write gtfs back to file
ptv_210805 <- as_tidygtfs(ptv_210805)
tidytransit::write_gtfs(ptv_210805, "data/ptv_210805/gtfs_duplicate_stops_removed.zip")

## convert to list of tidygtfs objects
ptv_210805_list_gtfs <- gtfssupplyindex::gtfs_by_route_type("data/ptv_210805/gtfs_duplicate_stops_removed.zip")

list_gtfs = ptv_210805_list_gtfs

areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)

```

```{r run_for_all_modes_Victoria_210810, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

si_by_area_and_hour_210810 <- hourly(
  list_gtfs = list_gtfs, 
  stops_in_or_near_areas = stops_in_or_near_areas, 
  date_ymd = "2021-08-10",
  verbose = TRUE)

write.csv(si_by_area_and_hour_210810, "results/Greater_Melbourne/si_by_SA12021area_and_hour_210810")

si_by_area_and_hour_210810_tram <- hourly(
  list_gtfs = list_gtfs[1], 
  stops_in_or_near_areas = stops_in_or_near_areas[1], 
  date_ymd = "2021-08-10",
  verbose = TRUE)

write.csv(si_by_area_and_hour_210810_tram, "results/Greater_Melbourne/si_by_SA12021area_and_hour_210810_tram")

si_by_area_and_hour_210810_rail <- hourly(
  list_gtfs = list_gtfs[2], 
  stops_in_or_near_areas = stops_in_or_near_areas[2], 
  date_ymd = "2021-08-10",
  verbose = TRUE)

write.csv(si_by_area_and_hour_210810_rail, "results/Greater_Melbourne/si_by_SA12021area_and_hour_210810_rail")

si_by_area_and_hour_210810_bus <- hourly(
  list_gtfs = list_gtfs[3], 
  stops_in_or_near_areas = stops_in_or_near_areas[3], 
  date_ymd = "2021-08-10",
  verbose = TRUE)

write.csv(si_by_area_and_hour_210810_bus, "results/Greater_Melbourne/si_by_SA12021area_and_hour_210810_bus")

```

```{r fix_ptv_data_Victoria_200729, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

ptv_200729 <- tidytransit::read_gtfs("data/ptv_200729/gtfs.zip")
# This results in "Warning: Duplicated ids found in: stops The returned object is not a tidygtfs object, you can use as_tidygtfs() after fixing the issue."

#So, remove the duplicated stops 
#identify duplicate stops
ptv_200729_duplicated_stops <- tabyl(ptv_200729$stops$stop_id) %>% filter (n>1)
names(ptv_200729_duplicated_stops) <- c("stop_id", "n", "percent")
ptv_200729_duplicated_stops <- left_join(ptv_200729_duplicated_stops, ptv_200729$stops)

##discard duplicates
ptv_200729$stops <- ptv_200729$stops[!duplicated(ptv_200729$stops$stop_id),]

## Write gtfs back to file
ptv_200729 <- as_tidygtfs(ptv_200729)
tidytransit::write_gtfs(ptv_200729, "data/ptv_200729/gtfs_duplicate_stops_removed.zip")

## convert to list of tidygtfs objects
ptv_200729_list_gtfs <- gtfssupplyindex::gtfs_by_route_type("data/ptv_200729/gtfs_duplicate_stops_removed.zip")

list_gtfs = ptv_200729_list_gtfs

areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)

```

```{r run_for_all_modes_Victoria_200811, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

si_by_area_and_hour_200811 <- hourly(
  list_gtfs = list_gtfs, 
  stops_in_or_near_areas = stops_in_or_near_areas, 
  date_ymd = "2020-08-11",
  verbose = TRUE)

write.csv(si_by_area_and_hour_200811, "results/Greater_Melbourne/si_by_SA12021area_and_hour_200811")

si_by_area_and_hour_200811_tram <- hourly(
  list_gtfs = list_gtfs[1], 
  stops_in_or_near_areas = stops_in_or_near_areas[1], 
  date_ymd = "2020-08-11",
  verbose = TRUE)

write.csv(si_by_area_and_hour_200811_tram, "results/Greater_Melbourne/si_by_SA12021area_and_hour_200811_tram")

si_by_area_and_hour_200811_rail <- hourly(
  list_gtfs = list_gtfs[2], 
  stops_in_or_near_areas = stops_in_or_near_areas[2], 
  date_ymd = "2020-08-11",
  verbose = TRUE)

write.csv(si_by_area_and_hour_200811_rail, "results/Greater_Melbourne/si_by_SA12021area_and_hour_200811_rail")

si_by_area_and_hour_200811_bus <- hourly(
  list_gtfs = list_gtfs[3], 
  stops_in_or_near_areas = stops_in_or_near_areas[3], 
  date_ymd = "2020-08-11",
  verbose = TRUE)

write.csv(si_by_area_and_hour_200811_bus, "results/Greater_Melbourne/si_by_SA12021area_and_hour_200811_bus")

```

```{r fix_ptv_data_Victoria_190802, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

ptv_190802 <- tidytransit::read_gtfs("data/ptv_190802/gtfs.zip")
# This results in "Warning: Duplicated ids found in: stops The returned object is not a tidygtfs object, you can use as_tidygtfs() after fixing the issue."

#So, remove the duplicated stops 
#identify duplicate stops
ptv_190802_duplicated_stops <- tabyl(ptv_190802$stops$stop_id) %>% filter (n>1)
names(ptv_190802_duplicated_stops) <- c("stop_id", "n", "percent")
ptv_190802_duplicated_stops <- left_join(ptv_190802_duplicated_stops, ptv_190802$stops)

##discard duplicates
ptv_190802$stops <- ptv_190802$stops[!duplicated(ptv_190802$stops$stop_id),]

## Write gtfs back to file
ptv_190802 <- as_tidygtfs(ptv_190802)
tidytransit::write_gtfs(ptv_190802, "data/ptv_190802/gtfs_duplicate_stops_removed.zip")

## convert to list of tidygtfs objects
ptv_190802_list_gtfs <- gtfssupplyindex::gtfs_by_route_type("data/ptv_190802/gtfs_duplicate_stops_removed.zip")

list_gtfs = ptv_190802_list_gtfs

areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)

```

```{r run_for_all_modes_Victoria_190813, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

si_by_area_and_hour_190813 <- hourly(
  list_gtfs = list_gtfs, 
  stops_in_or_near_areas = stops_in_or_near_areas, 
  date_ymd = "2019-08-13",
  verbose = TRUE)

write.csv(si_by_area_and_hour_190813, "results/Greater_Melbourne/si_by_SA12021area_and_hour_190813")

si_by_area_and_hour_190813_tram <- hourly(
  list_gtfs = list_gtfs[1], 
  stops_in_or_near_areas = stops_in_or_near_areas[1], 
  date_ymd = "2019-08-13",
  verbose = TRUE)

write.csv(si_by_area_and_hour_190813_tram, "results/Greater_Melbourne/si_by_SA12021area_and_hour_190813_tram")

si_by_area_and_hour_190813_rail <- hourly(
  list_gtfs = list_gtfs[2], 
  stops_in_or_near_areas = stops_in_or_near_areas[2], 
  date_ymd = "2019-08-13",
  verbose = TRUE)

write.csv(si_by_area_and_hour_190813_rail, "results/Greater_Melbourne/si_by_SA12021area_and_hour_190813_rail")

si_by_area_and_hour_190813_bus <- hourly(
  list_gtfs = list_gtfs[3], 
  stops_in_or_near_areas = stops_in_or_near_areas[3], 
  date_ymd = "2019-08-13",
  verbose = TRUE)

write.csv(si_by_area_and_hour_190813_bus, "results/Greater_Melbourne/si_by_SA12021area_and_hour_190813_bus")

```

```{r fix_ptv_data_Victoria_180803, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

ptv_180803 <- tidytransit::read_gtfs("data/ptv_180803/gtfs.zip")
# This results in "Warning: Duplicated ids found in: stops The returned object is not a tidygtfs object, you can use as_tidygtfs() after fixing the issue."

#So, remove the duplicated stops 
#identify duplicate stops
ptv_180803_duplicated_stops <- tabyl(ptv_180803$stops$stop_id) %>% filter (n>1)
names(ptv_180803_duplicated_stops) <- c("stop_id", "n", "percent")
ptv_180803_duplicated_stops <- left_join(ptv_180803_duplicated_stops, ptv_180803$stops)

##discard duplicates
ptv_180803$stops <- ptv_180803$stops[!duplicated(ptv_180803$stops$stop_id),]

## Write gtfs back to file
ptv_180803 <- as_tidygtfs(ptv_180803)
tidytransit::write_gtfs(ptv_180803, "data/ptv_180803/gtfs_duplicate_stops_removed.zip")

## convert to list of tidygtfs objects
ptv_180803_list_gtfs <- gtfssupplyindex::gtfs_by_route_type("data/ptv_180803/gtfs_duplicate_stops_removed.zip")

list_gtfs = ptv_180803_list_gtfs

areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)

```


```{r run_for_all_modes_Victoria_180814, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

si_by_area_and_hour_180814 <- hourly(
  list_gtfs = list_gtfs, 
  stops_in_or_near_areas = stops_in_or_near_areas, 
  date_ymd = "2018-08-14",
  verbose = TRUE)

write.csv(si_by_area_and_hour_180814, "results/Greater_Melbourne/si_by_SA12021area_and_hour_180814")

si_by_area_and_hour_180814_tram <- hourly(
  list_gtfs = list_gtfs[1], 
  stops_in_or_near_areas = stops_in_or_near_areas[1], 
  date_ymd = "2018-08-14",
  verbose = TRUE)

write.csv(si_by_area_and_hour_180814_tram, "results/Greater_Melbourne/si_by_SA12021area_and_hour_180814_tram")

si_by_area_and_hour_180814_rail <- hourly(
  list_gtfs = list_gtfs[2], 
  stops_in_or_near_areas = stops_in_or_near_areas[2], 
  date_ymd = "2018-08-14",
  verbose = TRUE)

write.csv(si_by_area_and_hour_180814_rail, "results/Greater_Melbourne/si_by_SA12021area_and_hour_180814_rail")

si_by_area_and_hour_180814_bus <- hourly(
  list_gtfs = list_gtfs[3], 
  stops_in_or_near_areas = stops_in_or_near_areas[3], 
  date_ymd = "2018-08-14",
  verbose = TRUE)

write.csv(si_by_area_and_hour_180814_bus, "results/Greater_Melbourne/si_by_SA12021area_and_hour_180814_bus")

```

```{r fix_ptv_data_Victoria_170804, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

ptv_170804 <- tidytransit::read_gtfs("data/ptv_170804/gtfs.zip")
# This results in "Warning: Duplicated ids found in: stops The returned object is not a tidygtfs object, you can use as_tidygtfs() after fixing the issue."

#So, remove the duplicated stops 
#identify duplicate stops
ptv_170804_duplicated_stops <- tabyl(ptv_170804$stops$stop_id) %>% filter (n>1)
names(ptv_170804_duplicated_stops) <- c("stop_id", "n", "percent")
ptv_170804_duplicated_stops <- left_join(ptv_170804_duplicated_stops, ptv_170804$stops)

##discard duplicates
ptv_170804$stops <- ptv_170804$stops[!duplicated(ptv_170804$stops$stop_id),]

## Write gtfs back to file
ptv_170804 <- as_tidygtfs(ptv_170804)
tidytransit::write_gtfs(ptv_170804, "data/ptv_170804/gtfs_duplicate_stops_removed.zip")

## convert to list of tidygtfs objects
ptv_170804_list_gtfs <- gtfssupplyindex::gtfs_by_route_type("data/ptv_170804/gtfs_duplicate_stops_removed.zip")

list_gtfs = ptv_170804_list_gtfs

areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)

```


```{r run_for_all_modes_Victoria_170808, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

si_by_area_and_hour_170808 <- hourly(
  list_gtfs = list_gtfs, 
  stops_in_or_near_areas = stops_in_or_near_areas, 
  date_ymd = "2017-08-08",
  verbose = TRUE)

write.csv(si_by_area_and_hour_170808, "results/Greater_Melbourne/si_by_SA12021area_and_hour_170808")

si_by_area_and_hour_170808_tram <- hourly(
  list_gtfs = list_gtfs[1], 
  stops_in_or_near_areas = stops_in_or_near_areas[1], 
  date_ymd = "2017-08-08",
  verbose = TRUE)

write.csv(si_by_area_and_hour_170808_tram, "results/Greater_Melbourne/si_by_SA12021area_and_hour_170808_tram")

si_by_area_and_hour_170808_rail <- hourly(
  list_gtfs = list_gtfs[2], 
  stops_in_or_near_areas = stops_in_or_near_areas[2], 
  date_ymd = "2017-08-08",
  verbose = TRUE)

write.csv(si_by_area_and_hour_170808_rail, "results/Greater_Melbourne/si_by_SA12021area_and_hour_170808_rail")

si_by_area_and_hour_170808_bus <- hourly(
  list_gtfs = list_gtfs[3], 
  stops_in_or_near_areas = stops_in_or_near_areas[3], 
  date_ymd = "2017-08-08",
  verbose = TRUE)

write.csv(si_by_area_and_hour_170808_bus, "results/Greater_Melbourne/si_by_SA12021area_and_hour_170808_bus")

```

```{r fix_ptv_data_Victoria_160804, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

ptv_160804 <- tidytransit::read_gtfs("data/ptv_160804/gtfs.zip")
# This results in "Warning: Duplicated ids found in: stops The returned object is not a tidygtfs object, you can use as_tidygtfs() after fixing the issue."

#So, remove the duplicated stops 
#identify duplicate stops
ptv_160804_duplicated_stops <- tabyl(ptv_160804$stops$stop_id) %>% filter (n>1)
names(ptv_160804_duplicated_stops) <- c("stop_id", "n", "percent")
ptv_160804_duplicated_stops <- left_join(ptv_160804_duplicated_stops, ptv_160804$stops)

##discard duplicates
ptv_160804$stops <- ptv_160804$stops[!duplicated(ptv_160804$stops$stop_id),]

## Write gtfs back to file
ptv_160804 <- as_tidygtfs(ptv_160804)
tidytransit::write_gtfs(ptv_160804, "data/ptv_160804/gtfs_duplicate_stops_removed.zip")

## convert to list of tidygtfs objects
ptv_160804_list_gtfs <- gtfssupplyindex::gtfs_by_route_type("data/ptv_160804/gtfs_duplicate_stops_removed.zip")

list_gtfs = ptv_160804_list_gtfs

areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)

```

```{r run_for_all_modes_Victoria_160809, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

si_by_area_and_hour_160809 <- hourly(
  list_gtfs = list_gtfs, 
  stops_in_or_near_areas = stops_in_or_near_areas, 
  date_ymd = "2016-08-09",
  verbose = TRUE)

write.csv(si_by_area_and_hour_160809, "results/Greater_Melbourne/si_by_SA12021area_and_hour_160809")

si_by_area_and_hour_160809_tram <- hourly(
  list_gtfs = list_gtfs[1], 
  stops_in_or_near_areas = stops_in_or_near_areas[1], 
  date_ymd = "2016-08-09",
  verbose = TRUE)

write.csv(si_by_area_and_hour_160809_tram, "results/Greater_Melbourne/si_by_SA12021area_and_hour_160809_tram")

si_by_area_and_hour_160809_rail <- hourly(
  list_gtfs = list_gtfs[2], 
  stops_in_or_near_areas = stops_in_or_near_areas[2], 
  date_ymd = "2016-08-09",
  verbose = TRUE)

write.csv(si_by_area_and_hour_160809_rail, "results/Greater_Melbourne/si_by_SA12021area_and_hour_160809_rail")

si_by_area_and_hour_160809_bus <- hourly(
  list_gtfs = list_gtfs[3], 
  stops_in_or_near_areas = stops_in_or_near_areas[3], 
  date_ymd = "2016-08-09",
  verbose = TRUE)

write.csv(si_by_area_and_hour_160809_bus, "results/Greater_Melbourne/si_by_SA12021area_and_hour_160809_bus")

```

```{r fix_ptv_data_Victoria_150729, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

ptv_150729 <- tidytransit::read_gtfs("data/ptv_150729/gtfs.zip")
# This results in "Warning: Duplicated ids found in: stops The returned object is not a tidygtfs object, you can use as_tidygtfs() after fixing the issue."

#So, remove the duplicated stops 
#identify duplicate stops
ptv_150729_duplicated_stops <- tabyl(ptv_150729$stops$stop_id) %>% filter (n>1)
names(ptv_150729_duplicated_stops) <- c("stop_id", "n", "percent")
ptv_150729_duplicated_stops <- left_join(ptv_150729_duplicated_stops, ptv_150729$stops)

##discard duplicates
ptv_150729$stops <- ptv_150729$stops[!duplicated(ptv_150729$stops$stop_id),]

## Write gtfs back to file
ptv_150729 <- as_tidygtfs(ptv_150729)
tidytransit::write_gtfs(ptv_150729, "data/ptv_150729/gtfs_duplicate_stops_removed.zip")

## convert to list of tidygtfs objects
ptv_150729_list_gtfs <- gtfssupplyindex::gtfs_by_route_type("data/ptv_150729/gtfs_duplicate_stops_removed.zip")

list_gtfs = ptv_150729_list_gtfs

areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)

```

```{r run_for_all_modes_Victoria_150811, eval = FALSE, echo = FALSE}
#eval is false, so as to not overwrite saved file

si_by_area_and_hour_150811 <- hourly(
  list_gtfs = list_gtfs, 
  stops_in_or_near_areas = stops_in_or_near_areas, 
  date_ymd = "2015-08-11",
  verbose = TRUE)

write.csv(si_by_area_and_hour_150811, "results/Greater_Melbourne/si_by_SA12021area_and_hour_150811")

si_by_area_and_hour_150811_tram <- hourly(
  list_gtfs = list_gtfs[1], 
  stops_in_or_near_areas = stops_in_or_near_areas[1], 
  date_ymd = "2015-08-11",
  verbose = TRUE)

write.csv(si_by_area_and_hour_150811_tram, "results/Greater_Melbourne/si_by_SA12021area_and_hour_150811_tram")

si_by_area_and_hour_150811_rail <- hourly(
  list_gtfs = list_gtfs[2], 
  stops_in_or_near_areas = stops_in_or_near_areas[2], 
  date_ymd = "2015-08-11",
  verbose = TRUE)

write.csv(si_by_area_and_hour_150811_rail, "results/Greater_Melbourne/si_by_SA12021area_and_hour_150811_rail")

si_by_area_and_hour_150811_bus <- hourly(
  list_gtfs = list_gtfs[3], 
  stops_in_or_near_areas = stops_in_or_near_areas[3], 
  date_ymd = "2015-08-11",
  verbose = TRUE)

write.csv(si_by_area_and_hour_150811_bus, "results/Greater_Melbourne/si_by_SA12021area_and_hour_150811_bus")

```

<!---
## Extensions?? 
Hourly
"Manhattan- and London-ised Indexes"


Tidytransit includes a sample GTFS feed from New York's MTA
(including the subway!), 
and so this was used for cod
e tests were appropriate. 
<MORE DETAILS ABOUT THIS>
--->


# Results
## Code structure

```{r SI_ERD, crop = TRUE, fig.cap = "Entity Relationship Diagram (ERD) showing the data structure and functions related to the gtfssupplyindex package", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, out.width='100%'}
knitr::include_graphics("graphics/SI_data_structure.png")

```


Developed code is available and documented on github [@gtfssupplyindex_github]. 
The structure of the package, 
functions developed, 
and data tables are shown in Figure \@ref(fig:SI_ERD), which shows  
how the package takes input from three files: 
a gtfs feed (gtfs.zip); 
a sf object describing the geometry of the areas 
for which the SI is to be calculated; and 
a csv file defining the buffer zone distances (in metres) 
for each route type^[This file is included in the package.]. The ultimate output 
is a si_by_area_and_hour table, 
which reports the SI score for each hour of the day 
across dates specified by the user. 

## Mornington Pennisula Tourist Railway
The various functions and their output 
and explained in the following, 
using the Mornington Peninsula GTFS for December 30th, 2018, and SA1 zone boundaries. 
Individual steps are:

(1) loading the gtfs.zip file: the gtfs_by_route_type function loads the gtfs data and splits it into a list (by route_type) of tidygtfs objects, using the filter_by_route_type function from the gtfstools package [@filter_GTFS_by_mode].

```{r load_mornington_GTFS data, echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, out.width='100%'}
#load the revised mornington GTFS data
list_gtfs = gtfssupplyindex:::gtfs_by_route_type(system.file(
  "extdata/mornington180109",
  "gtfs.zip", 
  package = "gtfssupplyindex", 
  mustWork = TRUE))

```

(2) loading geometry information about the areas of interest: geographical data about the areas of interest are loaded by the load_areas_of_interest.R function into an sf object, using the sf package [@R-sf]. The resultant areas_of_interest table contains each area_id and its associated geometry. 
Data about buffer zones, specifically the walking distance threshold assigned to each route_type (mode) is then loaded, again through a function (load_buffer_zone.R).

```{r load_ABS data, echo = FALSE, error = FALSE, include = FALSE, results='hide', warning=FALSE, message=FALSE, cache=TRUE, out.width='100%'}

suppressWarnings({
areas_of_interest <- load_areas_of_interest(areas_of_interest = sf::st_read(system.file(
  "extdata",
  "mornington_sa12021.geojson", 
  package = "gtfssupplyindex", 
  mustWork = TRUE)), 
  area_id_field = "sa1_code_2021")
})

#head(areas_of_interest) %>% kable(caption = "First 6 entries in areas of interest table")
```

```{r load_buffer_distance_data, echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, out.width='100%'}
buffer_distance <- gtfssupplyindex:::load_buffer_zones()
#head(buffer_distance) %>% kable(caption = "First six entries in buffer distance definitions")
```

(3) calculating which stops are within the catchment walking distance of which areas: using the stops_in_walk_dist function. Figure \@ref(fig:calculate_stop_in_or_near_areas_verbose)) shows an intermediate step in this is function, in which the SA1 areas within the 800 metre catchment of the Mornington stations is identifed. 

<!---However, this is complicated by the need to have different buffer distances for each route_type, and to only include those parts of the walking catchment that are within each area of interest. The calculation involves: (1) looking up the buffer_distance_length specific to each route_type; (2) transforming from latitude and longitude into metres and determining the area; (3) drawing circles around each stop, with the radius equal to the buffer distance, and intersecting these with the areas_of_interest (see Figure \@ref(fig:calculate_stop_in_or_near_areas_verbose)); (4) calculating the $area_{Bn}$ terms are for each combination of stop_id and area_id; and then reporting the overall area terms for each area_of_interest ($Area_{Bn} / Area_{Area}$), as shown in Table \ref@(tab:calculate_stop_in_or_near_areas).
--->


```{r calculate_stop_in_or_near_areas_verbose, echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, out.width='100%', fig.keep = "first", crop = TRUE, fig.cap= "Step 3, stop catchments for the Mornington Penninsula Tourist Railway, showing intersections with SA1 zones"}
stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355, 
  verbose = TRUE
)

```

```{r calculate_stop_in_or_near_areas, echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, out.width='100%'}
stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355, 
  verbose = FALSE
)

#head(stops_in_or_near_areas[[1]]) %>% kable(caption = "'Rail' element of the stops in or near areas list for the Mornington Pennisula datasets, first six entries")
```

<!-- The variables passed to the stop_in_or_near_areas function are list_gtfs^[The list of tidygtfs objects ouput by the gtfs_by_route_type function], the areas_of_interest table^[Which is the output of the load_areas_of_interest function], the buffer_distance table^[Output by the load_buffer_zones function], and an EPSG_for_transform variable. This last variable is the Coordinate Reference System (CRS) value relevant to the geographic location. It is used to project the latitude and longitude values included in the GTFS data and area_of_interest data into metres, in this case relating to the GDA94 / MGA zone 55 relevant to Australia^[https://epsg.io/28355].  

--->


(4) Calculating SI scores for a given time period: using the si_calc.R function. This adapts code from an article included in the tidytransit package [@tidytransit_departure_timetable] to calculate the number of arrivals in a given time period, and combines this with the calculated area components. The si_total.R and hourly.R functions provided aggregation, giving the results shown in Table \@ref(tab:SI_mornington_20181230_output) and mapped in Figure \@ref(fig:SI_mornington_20181230_output). 

```{r arrivals_mornington_20181230, echo = FALSE, eval=FALSE, warning=FALSE, message=FALSE, cache=TRUE}

stop_ids <- list_gtfs[[1]]$stops %>%
 dplyr::select(stop_id)

arrivals_by_stop_id <- gtfssupplyindex::arrivals(
 gtfs = list_gtfs[[1]],
 stop_ids = stop_ids,
 date_ymd = "2018-12-30",
 start_hms = lubridate::hms("10:30:00"),
 end_hms = lubridate::hms("16:00:00")
)

#arrivals_by_stop_id %>% kable(caption = "Arrivals at each stop for Sunday December 30th 2018, Mornington Peninsula tourist railway.")

```
<!--- This matches the number of trips shown in the Mornington Railway GTFS feed, being 4 in each direction^[https://transitfeeds.com/p/mornington-railway/806/latest/stop/1388695887/20181230]. 

```{r SI_Mornington_arrivals, fig.margin = FALSE, crop = TRUE, fig.cap = "Arrivals at Mornington Station (stop id 1388695887) for 30/12/2018", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, out.width='100%'}
knitr::include_graphics("graphics/1388695887_inbound.png")

```

All the inputs to calculate the si are now available. Hence, the SI.calc function can be run, resulting in the si_by_route_type list (by route_type) of tables showing the area_id corresponding SI values

```{r SI_mornington_20181230, echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}
####-----first load all the inputs

#load the revised mornington GTFS data
list_gtfs = gtfssupplyindex:::gtfs_by_route_type(system.file(
  "extdata/mornington180109",
  "gtfs.zip", 
  package = "gtfssupplyindex", 
  mustWork = TRUE))

areas_of_interest <- load_areas_of_interest(absmapsdata::sa22021 %>% filter(sa3_name_2021 == "Mornington Peninsula") %>% select(sa2_code_2021),  area_id_field = "sa2_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)

####----run SI.calc function to build si_by_mode_and_time list (by route_type) of tables

si_by_route_type <- si_calc(
    list_gtfs = list_gtfs,
    stops_in_or_near_areas = stops_in_or_near_areas, 
    date_ymd = lubridate::ymd("2018-12-30"), 
    start_hms = lubridate::hms("10:30:00"),
    end_hms = lubridate::hms("16:00:00"),
    verbose = TRUE)

si_by_route_type %>% kable(caption = "SI values for Mornington Penninsula Railway services on 30/12/2018 (full day)")

```

The si_total function aggregates the si_by_route_type tables so that values are no longer separated by mode. Although in the case of the Mornington Penninsula Railway there is only one route_type.  

Finally, the hourly function runs the si_calc and si_total functions for every hour in a single day. It outputs a table showing the SI scores for each area for each hour of the day^[Across the service span]. The below table shows this output, together with row and column totals.  

```{r SI_hourly_mornington_20181230, echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}

si_by_area_and_hour_wider <- hourly(list_gtfs, stops_in_or_near_areas, "2018-12-30")

si_by_area_and_hour_wider %>% adorn_totals(where = c("row", "col")) %>% kable(caption = "Mornington Penninsula Tourist Railway hourly SI values for December 30, 2018, for SA1 zones")

```
--->

```{r SI_mornington_20181230_output, echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, crop = TRUE, fig.cap = "Mornington Penninsula Tourist Railway hourly SI values for December 30, 2018"}
####-----first load all the inputs

#load the revised mornington GTFS data
list_gtfs = gtfssupplyindex:::gtfs_by_route_type(system.file(
  "extdata/mornington180109",
  "gtfs.zip", 
  package = "gtfssupplyindex", 
  mustWork = TRUE))

areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(sa3_name_2021 == "Mornington Peninsula") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

buffer_distance <- gtfssupplyindex:::load_buffer_zones()

stops_in_or_near_areas <- gtfssupplyindex:::stops_in_walk_dist(
  list_gtfs = list_gtfs, 
  areas_of_interest = areas_of_interest,
  EPSG_for_transform = 28355,
  verbose = FALSE
)


si_by_area_and_hour <- hourly(list_gtfs, stops_in_or_near_areas, "2018-12-30")


si_by_area_and_hour_wider <- pivot_wider(si_by_area_and_hour, names_from = hour_starting, values_from = SI)

#si_by_area_and_hour_wider %>% 
#  head() %>%
#  adorn_rounding() %>%
#  kable(caption = "Mornington Peninsula Tourist Railway hourly SI values for December 30, 2018")

map_areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(sa3_name_2021 == "Mornington Peninsula") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

#Join SI to map data
map_si_by_area_and_hour <- merge(map_areas_of_interest, si_by_area_and_hour)

map_si_by_area_and_hour <- na.omit(map_si_by_area_and_hour)

ggplot() + 
  geom_sf(data=map_si_by_area_and_hour,
          aes(fill = SI)) +
            facet_wrap(vars(hour_starting)) +
  theme(axis.text.x=element_blank(), #remove x axis labels
        axis.ticks.x=element_blank(), #remove x axis ticks
        axis.text.y=element_blank(),  #remove y axis labels
        axis.ticks.y=element_blank()  #remove y axis ticks
  )



```

<!--The results meet expectations, with higher scores for SA1 zones closer to the three stations. Hand calculation for SA1 21402159136, which is close to the Mornington Station, to confirm the results is relatively trivial. By inspection, all of SA1 21402159136 (shown in purple in Figure \@ref(fig:calculate_stop_in_or_near_areas_verbose) is within an 800 metre walking distance of Mornington Station, meaning that $Area_{Bn} / Area_{area} = 1$.  The SI scores for each hour are therefore equal to the number of arrivals in each hour.  Table \@ref(tab:mornington_hand_check) shows the scores calculated by the function, which matches the pattern of arrivals at 10:47am, 12:12pm, 2:02pm and 3:27pm^[See  https://transitfeeds.com/p/mornington-railway/806/latest/stops].

```{r mornington_hand_check, crop = TRUE, fig.cap = "Mornington Penninsula Railway GTFS summary", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, out.width='100%'}


si_by_area_and_hour_wider %>% 
  filter(area_id == "21402159136") %>%
  adorn_rounding() %>%
  kable(caption = "Mornington Penninsula Tourist Railway hourly SI values for December 30, 2018, for SA1 zone 21402159136")


#knitr::include_graphics("graphics/mornington_arrivals.png")



```

--->

## Central Melbourne

Figure \@ref(Melbourne_CBD_map_230808) shows SI scores for Tuesday August 8, 2023, by hour between 5am and 11am (top) and by mode for the whole day (bottom).  These generally expectations, with higher SI scores shown in the Central Business District (CBD), where there are the five stations that make up the City Loop: Flinders Street Station, Southern Cross Station, Flagstaff Station, Melbourne Central Station and Parliament Station; and where many tram and bus routes converge. The SI scores are highest between 7-9am, reflecting the typical service peaks. Results are also consistent with: the high number for bus services along the Victoria and Queen Street corridors; and tram services that mostly run along the Swanston, Elizabeth, Bourke and Collins Street corridors. 


```{r Melbourne_230808, echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}

###Load results from CSV (Precalculated above) and make first column character
si_by_area_and_hour_230808 <- read.csv("results/Greater_Melbourne/si_by_SA12021area_and_hour_230808")
si_by_area_and_hour_230808 <- si_by_area_and_hour_230808[,2:4]
si_by_area_and_hour_230808$area_id <- as.character(si_by_area_and_hour_230808$area_id)

#pivot to wider for display as table
si_by_area_and_hour_230808_wider <- si_by_area_and_hour_230808 %>% pivot_wider(names_from = hour_starting, values_from = SI)

#si_by_area_and_hour_230808_wider %>% select(1, 6:25) %>% head() %>% adorn_rounding(digits = 0) %>% kable(caption = "Victorian GTFS and SA1 zones within the Greater Melbourne GCCSA, hourly SI values for October 10, 2023, first 6 SA1 zones, 4am to 11pm only" )


```

```{r Melbourne_CBD_map_230808, fig.show="hold", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE, fig.fullwidth = TRUE, crop = TRUE, fig.cap="Victorian GTFS and central Melbourne SA1 zones, SI values for October 10, 2023, by hour between 5am and 11am (top) and by mode (bottom)"}

map_areas_of_interest <- load_areas_of_interest(absmapsdata::sa12021 %>% filter(sa4_name_2021 == "Melbourne - Inner") %>% select(sa1_code_2021),  area_id_field = "sa1_code_2021")

#Join SI to map data
map_si_by_area_and_hour_230808 <- inner_join(map_areas_of_interest, si_by_area_and_hour_230808)

#convert hour starting to numeric
map_si_by_area_and_hour_230808$hour_starting <- hm(map_si_by_area_and_hour_230808$hour_starting)
map_si_by_area_and_hour_230808$hour_starting <- hour(map_si_by_area_and_hour_230808$hour_starting)

xlim <- c(144.93343289587824,  144.9946369676684)
ylim <- c(-37.80347733938971, -37.82753754010771)

#plot only 5am to 10am
p1 <- ggplot() + 
  geom_sf(data=map_si_by_area_and_hour_230808 %>% filter(hour_starting %in% (8:10)),
          aes(fill = SI)) +
            facet_wrap(vars(hour_starting), nrow=1) +
  theme(axis.text.x=element_blank(), #remove x axis labels
        axis.ticks.x=element_blank(), #remove x axis ticks
        axis.text.y=element_blank(),  #remove y axis labels
        axis.ticks.y=element_blank()  #remove y axis ticks
  ) +
  coord_sf(xlim = xlim, ylim = ylim)  


###Load results from CSV (Precalculated above) and make first column character
si_by_area_and_hour_230808_tram <- read.csv("results/Greater_Melbourne/si_by_SA12021area_and_hour_230808_tram")
si_by_area_and_hour_230808_tram <- si_by_area_and_hour_230808_tram[,2:4]
si_by_area_and_hour_230808_tram$area_id <- as.character(si_by_area_and_hour_230808_tram$area_id)

si_by_area_and_hour_230808_rail <- read.csv("results/Greater_Melbourne/si_by_SA12021area_and_hour_230808_rail")
si_by_area_and_hour_230808_rail <- si_by_area_and_hour_230808_rail[,2:4]
si_by_area_and_hour_230808_rail$area_id <- as.character(si_by_area_and_hour_230808_rail$area_id)

si_by_area_and_hour_230808_bus <- read.csv("results/Greater_Melbourne/si_by_SA12021area_and_hour_230808_bus")
si_by_area_and_hour_230808_bus <- si_by_area_and_hour_230808_bus[,2:4]
si_by_area_and_hour_230808_bus$area_id <- as.character(si_by_area_and_hour_230808_bus$area_id)

### merge dataframes
si_by_area_and_hour_230808_tram$mode <- "Tram"
si_by_area_and_hour_230808_rail$mode <- "Rail"
si_by_area_and_hour_230808_bus$mode <- "Bus"

si_by_area_and_hour_230808_all_modes <- merge(si_by_area_and_hour_230808_tram, si_by_area_and_hour_230808_rail, all = TRUE)
si_by_area_and_hour_230808_all_modes <- merge(si_by_area_and_hour_230808_all_modes, si_by_area_and_hour_230808_bus,  all = TRUE)


#Join SI to map data
map_si_by_area_and_hour_230808_all_modes <- inner_join(map_areas_of_interest, si_by_area_and_hour_230808_all_modes)

#convert hour starting to numeric
map_si_by_area_and_hour_230808_all_modes$hour_starting <- hm(map_si_by_area_and_hour_230808_all_modes$hour_starting)
map_si_by_area_and_hour_230808_all_modes$hour_starting <- hour(map_si_by_area_and_hour_230808_all_modes$hour_starting)


#plot bus, tram and rail
p2 <- ggplot() + 
  geom_sf(data=map_si_by_area_and_hour_230808_all_modes,
          aes(fill = SI)) +
            facet_wrap(vars(mode), nrow=1) +
  theme(axis.text.x=element_blank(), #remove x axis labels
        axis.ticks.x=element_blank(), #remove x axis ticks
        axis.text.y=element_blank(),  #remove y axis labels
        axis.ticks.y=element_blank()  #remove y axis ticks
  ) +
  coord_sf(xlim = xlim, ylim = ylim) 

p1 / p2
```


 
## Greater Melbourne 


### By hour



```{r Melbourne_City_sa2_230808_by_hour, crop = TRUE, fig.cap = "Victorian GTFS and SA3 zones, SI values for Tuesday August 8, 2023, by hour, 5am to midnight", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}


#Join SI to ABS names data
si_by_area_and_hour_230808_sa2  <- left_join(
  si_by_area_and_hour_230808,
  (absmapsdata::sa12021 %>% 
     filter(gcc_name_2021 == "Greater Melbourne") %>% 
     select(sa1_code_2021, sa2_code_2021, sa2_name_2021, sa3_name_2021) %>%
     st_drop_geometry()), 
  by = join_by(area_id == sa1_code_2021)
)



#aggregate SI by SA2 for Melbourne City only
si_by_area_and_hour_230808_sa2 <- si_by_area_and_hour_230808_sa2 %>% 
  filter(sa3_name_2021 == "Melbourne City") %>%
  aggregate(SI ~ hour_starting+sa2_name_2021+sa3_name_2021,
  FUN = sum) %>%
  as_tibble()

#convert hour starting to numeric
si_by_area_and_hour_230808_sa2$hour_starting_numeric <- hm(si_by_area_and_hour_230808_sa2$hour_starting)
si_by_area_and_hour_230808_sa2$hour_starting_numeric <- hour(si_by_area_and_hour_230808_sa2$hour_starting_numeric)

ggwithinstats(
  data = si_by_area_and_hour_230808_sa2 %>% 
    filter(hour_starting_numeric > 5 & 
            hour_starting_numeric < 24),
  x = hour_starting_numeric,
  y = SI,
  #type = "nonparametric", ## type of statistical test
  xlab = "Hour starting", ## label for the x-axis
  ylab = "SI", ## label for the y-axis
  package = "yarrr", ## package from which color palette is to be taken
  palette = "info2", ## choosing a different color palette
  pairwise.display = "none"
)  
```



```{r Melbourne_230808_by_hour, crop = TRUE, fig.cap = "Victorian GTFS and SA3 zones (except Melbourne City), SI values for Tuesday August 8, 2023, by hour, 5am to midnight", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}


#Join SI to ABS names data
si_by_area_and_hour_230808_sa3  <- left_join(
  si_by_area_and_hour_230808,
  (absmapsdata::sa12021 %>% 
     filter(gcc_name_2021 == "Greater Melbourne") %>% 
     select(sa1_code_2021, sa3_code_2021, sa3_name_2021, sa4_name_2021) %>%
     st_drop_geometry()), 
  by = join_by(area_id == sa1_code_2021)
)



#aggregate SI by SA3
si_by_area_and_hour_230808_sa3 <- si_by_area_and_hour_230808_sa3 %>% 
  aggregate(SI ~ hour_starting+sa3_name_2021+sa4_name_2021,
  FUN = sum) %>%
  as_tibble()

#convert hour starting to numeric
si_by_area_and_hour_230808_sa3$hour_starting_numeric <- hm(si_by_area_and_hour_230808_sa3$hour_starting)
si_by_area_and_hour_230808_sa3$hour_starting_numeric <- hour(si_by_area_and_hour_230808_sa3$hour_starting_numeric)

ggwithinstats(
  data = si_by_area_and_hour_230808_sa3 %>% 
    filter(sa3_name_2021 != "Melbourne City") %>%
    filter(hour_starting_numeric > 5 & 
            hour_starting_numeric < 24),
  x = hour_starting_numeric,
  y = SI,
  #type = "nonparametric", ## type of statistical test
  xlab = "Hour starting", ## label for the x-axis
  ylab = "SI", ## label for the y-axis
  package = "yarrr", ## package from which color palette is to be taken
  palette = "info2", ## choosing a different color palette
  pairwise.display = "none"
)  

```


```{r greater_melbourne_230808_sa3_by_hour_percentatages, crop = TRUE, fig.cap = "Victorian GTFS and SA3 zones within Greater Melbourne, SI values for Tuesday August 8, 2023, by hour as a percentage of the full day", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}

si_by_area_and_hour_230808_sa3_wider <- si_by_area_and_hour_230808_sa3 %>%
  select(sa3_name_2021, hour_starting_numeric, SI) %>%
  pivot_wider(names_from = hour_starting_numeric, values_from = SI)


si_by_area_and_hour_230808_sa3_wider_percentages <- si_by_area_and_hour_230808_sa3_wider %>% 
  adorn_percentages() 

si_by_area_and_hour_230808_sa3_percentages <- si_by_area_and_hour_230808_sa3_wider_percentages %>% 
  pivot_longer(cols = 2:ncol(si_by_area_and_hour_230808_sa3_wider_percentages), 
               names_to = "hour_starting", 
               values_to = "SI")

si_by_area_and_hour_230808_sa3_percentages$hour_starting <- si_by_area_and_hour_230808_sa3_percentages$hour_starting %>% as.numeric()

ggwithinstats(
  data = si_by_area_and_hour_230808_sa3_percentages, ## data frame from which variables are taken
  x = hour_starting, ## predictor/independent variable
  y = SI, ## dependent variable
  xlab = "Population", ## label for the x-axis
  ylab = "SI score", ## label for the y-axis
  label.var = sa3_name_2021, ## variable to use for labeling data points
  # label.expression = Population > 15000 & SI < 5000, ## expression for deciding which points to label
  point.label.args = list(alpha = 0.7, size = 4, color = "grey50"),
  xfill = "#CC79A7", ## fill for marginals on the x-axis
  yfill = "#009E73", ## fill for marginals on the y-axis
  pairwise.display = "none"
) 

```



```{r greater_melbourne_230808_8am_versus_total_scatterplot, crop = TRUE, fig.cap = "Victorian GTFS and SA3 zones within Greater Melbourne (except Melbourne City), SI values for Tuesday August 8, 2023 8 to 9am versus all day", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}


ggscatterstats(
  data = si_by_area_and_hour_230808_sa3_wider_percentages,
  x = `8`, ## predictor/independent variable
  y = `20`, ## dependent variable
  xlab = "8-9am", ## label for the x-axis
  ylab = "8-9pm", ## label for the y-axis
  label.var = sa3_name_2021, ## variable to use for labeling data points
  # label.expression = Population > 15000 & SI < 5000, ## expression for deciding which points to label
  point.label.args = list(alpha = 0.7, size = 4, color = "grey50"),
  xfill = "#CC79A7", ## fill for marginals on the x-axis
  yfill = "#009E73", ## fill for marginals on the y-axis
) 

```



```{r greater_melbourne_230808_8am_versus_total_scatterplot, crop = TRUE, fig.cap = "Victorian GTFS and SA3 zones within Greater Melbourne (except Melbourne City), SI values for Tuesday August 8, 2023 8 to 9am versus all day", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}


si_by_area_and_hour_230808_sa3_wider <- si_by_area_and_hour_230808_sa3_wider %>% 
  adorn_totals(where = "col") 

ggscatterstats(
  data = si_by_area_and_hour_230808_sa3_wider %>% 
    filter(sa3_name_2021 != "Melbourne City"), ## data frame from which variables are taken
  x = `8`, ## predictor/independent variable
  y = Total, ## dependent variable
  xlab = "8-9am", ## label for the x-axis
  ylab = "Full day", ## label for the y-axis
  # label.var = sa3_name_2021, ## variable to use for labeling data points
  # label.expression = Population > 15000 & SI < 5000, ## expression for deciding which points to label
  point.label.args = list(alpha = 0.7, size = 4, color = "grey50"),
  xfill = "#CC79A7", ## fill for marginals on the x-axis
  yfill = "#009E73", ## fill for marginals on the y-axis
) 

```


```{r greater_melbourne_230808_5pm_versus_total_scatterplot, crop = TRUE, fig.cap = "Victorian GTFS and SA3 zones within Greater Melbourne (except Melbourne City), SI values for Tuesday August 8, 2023 5 to 6pm versus all day", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}

ggscatterstats(
  data = si_by_area_and_hour_230808_sa3_wider %>% 
    filter(sa3_name_2021 != "Melbourne City"), ## data frame from which variables are taken
  x = `5`, ## predictor/independent variable
  y = Total, ## dependent variable
  xlab = "5-6pm", ## label for the x-axis
  ylab = "Full day", ## label for the y-axis
   label.var = sa3_name_2021, ## variable to use for labeling data points
  # label.expression = Population > 15000 & SI < 5000, ## expression for deciding which points to label
  point.label.args = list(alpha = 0.7, size = 4, color = "grey50"),
  xfill = "#CC79A7", ## fill for marginals on the x-axis
  yfill = "#009E73", ## fill for marginals on the y-axis
) 

```


```{r greater_melbourne_230808_9pm_versus_total_scatterplot, crop = TRUE, fig.cap = "Victorian GTFS and SA3 zones within Greater Melbourne (except Melbourne City), SI values for Tuesday August 8, 2023 9 to 10pm versus all day", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}

ggscatterstats(
  data = si_by_area_and_hour_230808_sa3_wider %>% 
    filter(sa3_name_2021 != "Melbourne City"), ## data frame from which variables are taken
  x = `21`, ## predictor/independent variable
  y = Total, ## dependent variable
  xlab = "9-10pm", ## label for the x-axis
  ylab = "Full day", ## label for the y-axis
   label.var = sa3_name_2021, ## variable to use for labeling data points
  # label.expression = Population > 15000 & SI < 5000, ## expression for deciding which points to label
  point.label.args = list(alpha = 0.7, size = 4, color = "grey50"),
  xfill = "#CC79A7", ## fill for marginals on the x-axis
  yfill = "#009E73", ## fill for marginals on the y-axis
) 

```

### Location, population and equality of service

```{r gghistostats_greater_melbourne_230808, crop = TRUE, fig.cap = "Victorian GTFS and SA1 zones within Greater Melbourne, SI values for Tuesday August 8, 2023", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}

#aggregate SI by area
si_by_area_230808 <- si_by_area_and_hour_230808 %>%
  aggregate(SI ~ area_id, FUN = sum) %>%
  as_tibble()


#Join SI to ABS names data
si_by_area_230808 <- left_join(si_by_area_230808, 
                               (absmapsdata::sa12021 %>% 
                                 filter(gcc_name_2021 == "Greater Melbourne") %>% 
                                 select(sa1_code_2021, sa3_name_2021, sa4_name_2021,
                                        areasqkm_2021, cent_lat, cent_long) %>%
                                 st_drop_geometry()), 
                               by = join_by(area_id == sa1_code_2021)
)

#aggregate SI by SA3
si_by_area_230808_sa3 <- si_by_area_230808 %>%
  aggregate(SI ~ sa3_name_2021, FUN = sum) %>%
  as_tibble()


#Join SI to ABS names data
si_by_area_230808_sa3 <- left_join(si_by_area_230808_sa3, 
                               (absmapsdata::sa32021 %>% 
                                 filter(gcc_name_2021 == "Greater Melbourne") %>% 
                                 select(sa3_name_2021, sa3_code_2021, sa4_name_2021) %>%
                                 st_drop_geometry()), 
                               by = join_by(sa3_name_2021 == sa3_name_2021)
)



#Join SI to map data
map_areas_of_interest_sa3 <- absmapsdata::sa32021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa3_name_2021, sa4_name_2021, geometry)

map_si_by_area_230808_sa3 <- inner_join(map_areas_of_interest_sa3, si_by_area_230808_sa3)


#load_population_data
X2021Census_G01_VIC_SA1 <- read_csv(
  "data/2021_GCP_SA1_for_VIC_short-header/2021 Census GCP Statistical Area 1 for VIC/2021Census_G01_VIC_SA1.csv")
X2021Census_G01_VIC_SA1$SA1_CODE_2021 <- as.character(
  X2021Census_G01_VIC_SA1$SA1_CODE_2021)


#aggregate SI by area
si_by_area_230808 <- si_by_area_and_hour_230808 %>%
  aggregate(SI ~ area_id, FUN = sum) %>%
  as_tibble()


#join_to_SI_scores
si_by_area_230808_pop <- left_join(si_by_area_230808,
                               (X2021Census_G01_VIC_SA1 %>% 
                                  select(SA1_CODE_2021, Tot_P_P)), 
                                by = join_by(area_id == SA1_CODE_2021)
                                )

names(si_by_area_230808_pop) <- c("area_id", "SI", "Population")



#Join SI to ABS names data
si_by_area_230808_pop <- left_join(si_by_area_230808_pop, 
                               (absmapsdata::sa12021 %>% 
                                 filter(gcc_name_2021 == "Greater Melbourne") %>% 
                                 select(sa1_code_2021, sa3_name_2021, sa4_name_2021) %>%
                                 st_drop_geometry()), 
                               by = join_by(area_id == sa1_code_2021)
)


#si_by_area_230808_pop %>% 
#  select(Population, SI) %>%
#  tbl_summary(type = all_continuous() ~ "continuous2",
#    statistic = all_continuous() ~ c("{median} ({p25}, {p75})", "{Skew}", "{mean} ({sd})", "{p10}, {p90}", "{p5}, {p95}", "{p1},{p99}","{min},{max}")
#  ) 



#ggscatterstats(
#  data = si_by_area_230808_pop, ## data frame from which variables are taken
#  x = Population, ## predictor/independent variable
#  y = SI, ## dependent variable
#  xlab = "Population", ## label for the x-axis
#  ylab = "SI score", ## label for the y-axis
#  label.var = sa3_name_2021, ## variable to use for labeling data points
#  label.expression = Population > 600 & SI < 30, ## expression for deciding which points to label
#  point.label.args = list(alpha = 0.7, size = 4, color = "grey50"),
#  xfill = "#CC79A7", ## fill for marginals on the x-axis
#  yfill = "#009E73", ## fill for marginals on the y-axis
#) +
#  scale_x_log10() +
# scale_y_log10()



```

```{r Gini_coefficients, crop = TRUE, fig.cap = "Victorian GTFS and SA1 zones within Greater Melbourne, SI values for Tuesday August 8, 2023, Lorenz plot", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}


ggplot(si_by_area_230808_pop %>% 
        select(SI, Population), 
       aes(x = SI, n = Population)) + 
         stat_lorenz()  +
  geom_abline(linetype = "dashed") +
  theme_bw() +
  labs(x = "Cumulative share of Population", y = "Cumulative share of SI") +
  #scale_x_continuous(labels = scales::percent()) + 
  #scale_y_continuous(labels = scales::percent()) + 
  annotate_ineq(data_ineq = (si_by_area_230808_pop %>% 
        select(SI, Population))$SI, 
                freq_ineq = (si_by_area_230808_pop %>% 
        select(SI, Population))$Population,
                measure_ineq = "Gini", 
                color = "red",
                family = theme_get()$text[["family"]],
                size = theme_get()$text[["size"]] / 2,
                fontface = "italic") 



```


```{r map_greater_melbourne_230808_by_sa3, crop = TRUE, fig.cap = "Victorian GTFS and SA3 zones within Greater Melbourne, SI values for Tuesday August 8, 2023 (left) and 2021 census population (right)", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}


map_areas_of_interest_sa3 <- absmapsdata::sa32021 %>% filter(gcc_name_2021 == "Greater Melbourne") %>% select(sa3_name_2021, sa4_name_2021, geometry)

#Join SI to map data
map_si_by_area_230808_sa3 <- inner_join(map_areas_of_interest_sa3,
                                        si_by_area_230808_sa3)



my_breaks = c(1, 10, 100, 1000, 10000, 100000, 1000000)

#plot
p5 <- ggplot() + 
  geom_sf(data=map_si_by_area_230808_sa3,
          aes(fill = SI)) + 
  theme(axis.text.x=element_blank(), #remove x axis labels
        axis.ticks.x=element_blank(), #remove x axis ticks
        axis.text.y=element_blank(),  #remove y axis labels
        axis.ticks.y=element_blank()  #remove y axis ticks
  ) +
  scale_fill_gradient(name = "SI", trans = "log", breaks = my_breaks, labels = my_breaks)


#aggregate SI by area
si_by_area_230808_pop_sa3 <- si_by_area_230808_pop %>%
  aggregate(Population ~ sa3_name_2021, FUN = sum) %>%
  as_tibble()

#Join Population to SI and map data
map_si_by_area_230808_sa3 <- inner_join(map_si_by_area_230808_sa3,
                                        si_by_area_230808_pop_sa3)


map_si_by_area_230808_sa3 %>% 
  st_drop_geometry() %>%
  select(Population, SI) %>%
  tbl_summary(type = all_continuous() ~ "continuous2",
    statistic = all_continuous() ~ c("{median} ({p25}, {p75})", "{Skew}", "{mean} ({sd})", "{p10}, {p90}", "{p5}, {p95}", "{p1}, {p99}","{min}, {max}")
  ) 

my_breaks = c(10, 100, 1000, 10000, 100000, 200000)


#plot
p6 <- ggplot() + 
  geom_sf(data=map_si_by_area_230808_sa3,
          aes(fill = Population)) + 
  theme(axis.text.x=element_blank(), #remove x axis labels
        axis.ticks.x=element_blank(), #remove x axis ticks
        axis.text.y=element_blank(),  #remove y axis labels
        axis.ticks.y=element_blank()  #remove y axis ticks
  ) +
  scale_fill_gradient(name = "Population", trans = "log", breaks = my_breaks, labels = my_breaks)




#plot
p7 <- ggplot() + 
  geom_sf(data=map_si_by_area_230808_sa3,
          aes(fill = log(SI / Population))) + 
  theme(axis.text.x=element_blank(), #remove x axis labels
        axis.ticks.x=element_blank(), #remove x axis ticks
        axis.text.y=element_blank(),  #remove y axis labels
        axis.ticks.y=element_blank()  #remove y axis ticks
  ) 

p5 + p6


```

```{r greater_melbourne_230808_by_sa3_scatterplot, crop = TRUE, fig.cap = "Victorian GTFS and SA3 zones within Greater Melbourne, SI values for Tuesday August 8, 2023 and 2021 census population (left), and log(SI divided by population) (right)", echo = FALSE, warning=FALSE, message=FALSE, cache=TRUE}



p8 <- ggscatterstats(
  data = map_si_by_area_230808_sa3 %>% st_drop_geometry(), ## data frame from which variables are taken
  x = Population, ## predictor/independent variable
  y = SI, ## dependent variable
  xlab = "Population", ## label for the x-axis
  ylab = "SI score", ## label for the y-axis
  label.var = sa3_name_2021, ## variable to use for labeling data points
  # label.expression = Population > 15000 & SI < 5000, ## expression for deciding which points to label
  point.label.args = list(alpha = 0.7, size = 4, color = "grey50"),
  xfill = "#CC79A7", ## fill for marginals on the x-axis
  yfill = "#009E73", ## fill for marginals on the y-axis
) +
  scale_x_log10() +
  scale_y_log10()

p8 + p7

```


### By year

 





# Extensions
## Melbourne CBD Index

## New York Index

## London Index



# Discussion and conclusions




# References {-}



```{r, include=FALSE}
knitr::write_bib(file = 'packages.bib')
```

